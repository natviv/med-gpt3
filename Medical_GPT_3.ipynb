{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/natviv/med-gpt3/blob/main/Medical_GPT_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYsx3i8kZK6F"
      },
      "source": [
        "# Medical GPT-3. \n",
        "\n",
        "This colab features an exploration of potential medical applications with GPT-3.\n",
        "\n",
        "The following applications are prototyped and explored.\n",
        "\n",
        "*   Convert clinical notes with abbreviations to patient readable format\n",
        "*   Convert free text patient conversations into structured format\n",
        "*   A primary care conversational agent that triages with a patient"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5SXT33waILE"
      },
      "source": [
        "This is built using Open AI API's integration with Weights and Biases (W&B)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leuRS_UuabbS"
      },
      "source": [
        "## API key setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-LMVGYzOvgh"
      },
      "outputs": [],
      "source": [
        "# API key credentials\n",
        "%env OPENAI_API_KEY="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "844rRfGfaemZ"
      },
      "source": [
        "## Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWs9EEwqGb1j",
        "outputId": "420522fc-2655-4b5b-c251-c55431729f49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.18.1.tar.gz (42 kB)\n",
            "\u001b[?25l\r\u001b[K     |███████▊                        | 10 kB 21.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 20 kB 25.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 30 kB 14.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 40 kB 13.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 42 kB 852 kB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.12.16-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 23.1 MB/s \n",
            "\u001b[?25hCollecting pandas-stubs>=1.1.0.11\n",
            "  Downloading pandas_stubs-1.2.0.58-py3-none-any.whl (162 kB)\n",
            "\u001b[K     |████████████████████████████████| 162 kB 57.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: openpyxl>=3.0.7 in /usr/local/lib/python3.7/dist-packages (from openai) (3.0.9)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.7/dist-packages (from openai) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from openai) (4.64.0)\n",
            "Requirement already satisfied: pandas>=1.2.3 in /usr/local/lib/python3.7/dist-packages (from openai) (1.3.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl>=3.0.7->openai) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai) (2022.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from pandas-stubs>=1.1.0.11->openai) (4.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.3->openai) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (1.24.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 59.2 MB/s \n",
            "\u001b[?25hCollecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.5.12-py2.py3-none-any.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 55.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.2.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: openai, pathtools\n",
            "  Building wheel for openai (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.18.1-py3-none-any.whl size=53168 sha256=9ca511222b1f239e0820399bf29658a58dc9547f97bb08d57e2c35fe647a2ff5\n",
            "  Stored in directory: /root/.cache/pip/wheels/5a/bf/24/fcdc9d2b81f9c7e565bb2036ec9f7cc930056b829895b3bf48\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=6318660e707b9712142a2ab5b04b10e80fb4d24478582736959eb6fbf3b56b9f\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built openai pathtools\n",
            "Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, pandas-stubs, GitPython, docker-pycreds, wandb, openai\n",
            "Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 openai-0.18.1 pandas-stubs-1.2.0.58 pathtools-0.1.2 sentry-sdk-1.5.12 setproctitle-1.2.3 shortuuid-1.0.9 smmap-5.0.0 wandb-0.12.16\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade openai wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "96T5DB0OJmxw"
      },
      "outputs": [],
      "source": [
        "# Setup imports\n",
        "\n",
        "import json\n",
        "import numpy as np\n",
        "import openai\n",
        "import os\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "wVBWaQVVIYDw",
        "outputId": "1a621ff2-4f59-48dd-9abb-e9e8d994a9c2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220516_053056-39nwpczm</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/natviv-gpt/Medical%20GPT-3/runs/39nwpczm\" target=\"_blank\">youthful-yogurt-10</a></strong> to <a href=\"https://wandb.ai/natviv-gpt/Medical%20GPT-3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "run = wandb.init(project='Medical GPT-3', job_type=\"dataset_preparation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Connect to dataset in Google Drive"
      ],
      "metadata": {
        "id": "slpjt06ZNUCJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_teDrgyTNbMm",
        "outputId": "f5de86ef-ccdb-4a1e-8bcb-ad4e3c6e671f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read data into pandas csv"
      ],
      "metadata": {
        "id": "vZTAZQ2ZNkrn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('gdrive/MyDrive/med-gpt3-data/data.csv')"
      ],
      "metadata": {
        "id": "uZAt16PKNn4X"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analyze data"
      ],
      "metadata": {
        "id": "LlSjB1aqi897"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of rows is {len(df)} and number of columns is {len(df.columns)}\")\n",
        "for index, row in df.iterrows():\n",
        "    print(f\"ID: {row['ID']}, Text: {row['Text']}, Completion: {row['Completion']}\")\n",
        "\n",
        "df_test = df.iloc[:5,:]\n",
        "df_train = df.iloc[5:,:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qg1TR3yPi_vZ",
        "outputId": "829cbe5f-d332-4e27-f93c-c8d570558163"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows is 30 and number of columns is 3\n",
            "ID: 1, Text: The pt has lbp, Completion: The patient has lower back pain\n",
            "ID: 2, Text: The pt is a 30 y/o m, Completion: The patient is a 30 year old male\n",
            "ID: 3, Text: VSS after Tx, Completion: Vital signs stable after treatment\n",
            "ID: 4, Text: c/o gi pain, Completion: complains of gastrointestinal pain\n",
            "ID: 5, Text: tx d/c due to c/o h/a, Completion: Treatment discontinued due to compaints of headache\n",
            "ID: 6, Text: abx dosage recommended, Completion: Antibiotics dosage recommended\n",
            "ID: 7, Text: thx required, Completion: therapy required\n",
            "ID: 8, Text: The pt requires lbp pt, Completion: The patient requires lower back pain physical therapy\n",
            "ID: 9, Text: MBC likely impaired due to covid, Completion: Maximum breathing capacity likely impaired due to covid\n",
            "ID: 10, Text: The pt has recurring history of jt pain, Completion: The patient has recurring history of joint pain\n",
            "ID: 11, Text: Nacl low in pt, Completion: Sodium chloride low in patient\n",
            "ID: 12, Text: LOS = 18 days, Completion: Lenght of stay = 18 days\n",
            "ID: 13, Text: LOC low, pt likely in coma, Completion: Level of consciouness low, patient likely in coma\n",
            "ID: 14, Text: PA will recommend next steps, Completion: Physician's Assistant will recommend next steps\n",
            "ID: 15, Text: NSA detected, Completion: No specific abnormality detected\n",
            "ID: 16, Text: The Pt when admitted was PN, Completion: The patient when admitted was pourly nourished\n",
            "ID: 17, Text: PN on duty administered the drugs, Completion: Practical nurse on duty administered the drugs\n",
            "ID: 18, Text: Low o2 sat. detected in pt, Completion: Low oxygen saturation detected in patient\n",
            "ID: 19, Text: PTA, vss were not normal, Completion: Prior to admission, vital signs were not normal\n",
            "ID: 20, Text: UTI as primary cause of fever, Completion: Urinary tract infection as primary cause of fever\n",
            "ID: 21, Text: Pt put on vent, Completion: Patient put on ventilator\n",
            "ID: 22, Text: fx detected in femur, Completion: fracture detected in femur\n",
            "ID: 23, Text: GNA to assist in care of pt, Completion: Geriatric Nurse Assistant to assist in care of patient\n",
            "ID: 24, Text: GCS low at admission, Completion: Glasgow Coma scale low at admission\n",
            "ID: 25, Text: Gt. tr required for pt, Completion: Gait training required for patient\n",
            "ID: 26, Text: Pt dc ama, Completion: Patient discharged against medical advice\n",
            "ID: 27, Text: CXR required to assess tx, Completion: Chest x-ray required to assess treatment\n",
            "ID: 28, Text: PET inconclusive, Completion: positron emission\n",
            "tomography inconclusive\n",
            "ID: 29, Text: oe pt recommended to be placed under obs for 24 hours, Completion: On examination, patient recommended to placed under observation for 24 hours\n",
            "ID: 30, Text: pt dnka, Completion: Patient did not keep appointment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use completion API to see how the 'text-davinci-002' model performs. Try with the following approaches:\n",
        "\n",
        "* Zero shot with only instruction\n",
        "* Few shot in-context learning \n",
        "* Few shot with chain of thought prompting -> https://arxiv.org/abs/2201.11903"
      ],
      "metadata": {
        "id": "CQ1qGm5RmwJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# This can be made more efficient and converted into a few batch calls\n",
        "def get_predictions(df, model, context, temperature=0.1, max_tokens=20, use_qa_prefix=False):\n",
        "  results = []\n",
        "  for _, row in tqdm(df.iterrows()):\n",
        "      input = row['Text'] if not use_qa_prefix else row['Text'] + 'Q:'\n",
        "      prompt = context + input + ' ->'\n",
        "      res = openai.Completion.create(model=model, \n",
        "                                     prompt=prompt, \n",
        "                                     max_tokens=max_tokens, \n",
        "                                     temperature = temperature, \n",
        "                                     stop=[\" END\"])\n",
        "      completion = res['choices'][0]['text']\n",
        "      completion = completion[1:] # remove initial space\n",
        "      results.append(f\"Text: {row['Text']}, Target: {row['Completion']}, Prediction: {completion}\")\n",
        "  return results\n",
        "\n",
        "def print_results(results): \n",
        "  for row in results:\n",
        "    print(f\"\\n{row}\")\n",
        "\n",
        "model = 'text-davinci-002'\n",
        "# Zero-shot with only instruction prompt\n",
        "instruction = 'Convert the doctor note into patient readable format without abbreviations.\\n'\n",
        "results = get_predictions(df_test, model, instruction)\n",
        "print_results(results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5SBqIpPmB_A",
        "outputId": "0f2076d7-b06c-4d4c-e9c8-ed5c3cb1a61b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5it [00:07,  1.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Text: The pt has lbp, Target: The patient has lower back pain, Prediction: The patient has low back pain.\n",
            "\n",
            "Text: The pt is a 30 y/o m, Target: The patient is a 30 year old male, Prediction: The patient is a 30 year old male.\n",
            "\n",
            "Text: VSS after Tx, Target: Vital signs stable after treatment, Prediction: VSS (visual acuity) after treatment\n",
            "\n",
            "The patient's visual acuity was 20/\n",
            "\n",
            "Text: c/o gi pain, Target: complains of gastrointestinal pain, Prediction: complaining of gastrointestinal pain\n",
            "\n",
            "Text: tx d/c due to c/o h/a, Target: Treatment discontinued due to compaints of headache, Prediction: \n",
            "The doctor has discharged me from the hospital due to my complaints of headaches.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zero shot with instruction only prompting seems to generate spurious results particularly beyond the length necessary. Lets see if this can be fixed with some in-context learning examples in addition to the instruction.\n",
        "\n",
        "In the above scenario, only 2/5 are correct and model can be seen rambling along in a couple."
      ],
      "metadata": {
        "id": "VBC7A7ig2fJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instruction = 'Convert the doctor note into patient readable format without abbreviations.\\n'\n",
        "example1 = 'The pt exhibits symptoms of CAD -> The patient exhibits symptoms of Coronary Artery Disease\\n'\n",
        "example2 = 'Pt has prior history of hbp -> Patient has prior history of high blood pressure\\n'\n",
        "\n",
        "# Few-shot in-context learning with instruction prompt and additional few shot examples\n",
        "context = instruction + example1 + example2\n",
        "results = get_predictions(df_test, model, context)\n",
        "print_results(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Qgc32X23lnn",
        "outputId": "63d77814-eb52-4a28-858b-5074312b6272"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5it [00:03,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Text: The pt has lbp, Target: The patient has lower back pain, Prediction: The patient has low back pain\n",
            "\n",
            "Text: The pt is a 30 y/o m, Target: The patient is a 30 year old male, Prediction: The patient is a 30 year old male\n",
            "\n",
            "Text: VSS after Tx, Target: Vital signs stable after treatment, Prediction: Vital Signs Stable after treatment\n",
            "\n",
            "Text: c/o gi pain, Target: complains of gastrointestinal pain, Prediction: complains of gastrointestinal pain\n",
            "\n",
            "The patient exhibits symptoms of Coronary Artery Disease. The patient\n",
            "\n",
            "Text: tx d/c due to c/o h/a, Target: Treatment discontinued due to compaints of headache, Prediction: Treatment was discontinued due to complaint of headache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### After in-context learning with only a couple of examples, the model seems to have improved quite significantly. \n",
        "\n",
        "Now the model is able to get 4/5 out of 5 examples correct and the rambling / tendency to generate long sentences seems to have reduced significantly."
      ],
      "metadata": {
        "id": "ujBwg8KIZIax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instruction = 'Convert the doctor note into patient readable format without abbreviations.\\n'\n",
        "example1 = 'Q: The pt exhibits symptoms of CAD -> A: The patient exhibits symptoms of Coronary Artery Disease. Explanation: Here pt stands for patient and CAD stands for Coronary Artery Disease.\\n'\n",
        "example2 = 'Q: Pt has prior history of hbp -> A: Patient has prior history of high blood pressure. Explanation: Here pt stands for patient and hbp stands for high blood pressure.\\n'\n",
        "\n",
        "# Few-shot in-context learning with instruction prompt and additional few shot examples with chain of thought prompting\n",
        "context = instruction + example1 + example2\n",
        "results = get_predictions(df_test, model, context, temperature=0.4, max_tokens=30)\n",
        "print_results(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PBXgZxHZvBK",
        "outputId": "afcb7679-43c2-4ffa-bda7-f648a1a73e01"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5it [00:09,  1.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Text: The pt has lbp, Target: The patient has lower back pain, Prediction: A: The patient has low back pain. Explanation: Here pt stands for patient and lbp stands for low back pain.\n",
            "\n",
            "Text: The pt is a 30 y/o m, Target: The patient is a 30 year old male, Prediction: The patient is a 30 year old male. Explanation: Here pt stands for patient and y/o stands for years old. m stands for male\n",
            "\n",
            "Text: VSS after Tx, Target: Vital signs stable after treatment, Prediction: A: VSS after treatment. Explanation: Here Tx stands for treatment.\n",
            "\n",
            "Text: c/o gi pain, Target: complains of gastrointestinal pain, Prediction: complains of gastrointestinal pain\n",
            "\n",
            "Text: tx d/c due to c/o h/a, Target: Treatment discontinued due to compaints of headache, Prediction: \n",
            "The patient was discharged from the hospital due to complaints of a headache.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chain of thought prompting doesn't seem to be super useful here. Perhaps this is due to the simple nature of the task.\n",
        "\n",
        "However, it is interesting to see inoherent explanations co-relate with in-correct model outputs. This suggests one mechanism to consider using models in medical applications might be to check whether the explanations / proof of work are coherent or not."
      ],
      "metadata": {
        "id": "leuIn4xSdk-x"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWbuwCDvUPLl"
      },
      "source": [
        "### Now let's see if finetuning a smaller model can help with improving the performance. \n",
        "\n",
        "Trying finetuning with a modest number of examples (20) as this is primarily for demonstration purposes.\n",
        "\n",
        "Using Weights & Biases integration for model training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "64b5fd91a47d43da9b22c50bd3a79308",
            "5b0ff84a2d3b4dd281288dff2b66d47d",
            "67d112657d424193ad0e08bbce710103",
            "014665d71776438095e94adef9415b05",
            "ab5d3b80f70a40e084ad7c1bc6279fda",
            "9a849292fac44c59ae9cadcab67d3178",
            "77ffe1251c7a4f5b8f9d2cf1e3889546",
            "b73a3767d60b4bb4bc25e5e678b9a76a"
          ]
        },
        "id": "Q2KYJVLeURpe",
        "outputId": "d2f23f76-b563-4405-c9cd-bec5285860ca"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:39nwpczm) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "64b5fd91a47d43da9b22c50bd3a79308"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">youthful-yogurt-10</strong>: <a href=\"https://wandb.ai/natviv-gpt/Medical%20GPT-3/runs/39nwpczm\" target=\"_blank\">https://wandb.ai/natviv-gpt/Medical%20GPT-3/runs/39nwpczm</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220516_053056-39nwpczm/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:39nwpczm). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220516_053356-w3kteljm</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/natviv-gpt/Medical%20GPT-3/runs/w3kteljm\" target=\"_blank\">icy-waterfall-11</a></strong> to <a href=\"https://wandb.ai/natviv-gpt/Medical%20GPT-3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "run = wandb.init(project='Medical GPT-3')\n",
        "\n",
        "# artifact = run.use_artifact('/content/gdrive/MyDrive/med-gpt3-data/data.csv', type='raw_dataset')\n",
        "# artifact_dir = artifact.download()+\"/data.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "WH4JxQ2wnxVe",
        "outputId": "68043d0d-6f0e-4a9f-825e-354f32cb7c08"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    ID                                             Prompt  \\\n",
              "2    3                                       VSS after Tx   \n",
              "28  29  oe pt recommended to be placed under obs for 2...   \n",
              "13  14                       PA will recommend next steps   \n",
              "10  11                                     Nacl low in pt   \n",
              "26  27                          CXR required to assess tx   \n",
              "\n",
              "                                           Completion  \n",
              "2                  Vital signs stable after treatment  \n",
              "28  On examination, patient recommended to placed ...  \n",
              "13    Physician's Assistant will recommend next steps  \n",
              "10                     Sodium chloride low in patient  \n",
              "26           Chest x-ray required to assess treatment  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3ab25e8d-a1be-497a-b1ab-75607b551055\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Prompt</th>\n",
              "      <th>Completion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>VSS after Tx</td>\n",
              "      <td>Vital signs stable after treatment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>29</td>\n",
              "      <td>oe pt recommended to be placed under obs for 2...</td>\n",
              "      <td>On examination, patient recommended to placed ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>PA will recommend next steps</td>\n",
              "      <td>Physician's Assistant will recommend next steps</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>Nacl low in pt</td>\n",
              "      <td>Sodium chloride low in patient</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>27</td>\n",
              "      <td>CXR required to assess tx</td>\n",
              "      <td>Chest x-ray required to assess treatment</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ab25e8d-a1be-497a-b1ab-75607b551055')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3ab25e8d-a1be-497a-b1ab-75607b551055 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3ab25e8d-a1be-497a-b1ab-75607b551055');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "#Shuffling the dataset with fixed seed\n",
        "\n",
        "df = pd.read_csv('gdrive/MyDrive/med-gpt3-data/data.csv')\n",
        "ds = df.sample(frac=1.0, random_state=0)\n",
        "ds.rename(columns={'Text': 'Prompt'}, inplace=True)\n",
        "ds.to_csv(\"data.csv\")\n",
        "ds.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsXVxE95RPS6"
      },
      "source": [
        "### Using OpenAI tools to preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0dY1ieyQAZV",
        "outputId": "207141e4-15d0-4a43-81d7-e8664e62dd4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing...\n",
            "\n",
            "- Based on your file extension, your file is formatted as a CSV file\n",
            "- Your file contains 30 prompt-completion pairs. In general, we recommend having at least a few hundred examples. We've found that performance tends to linearly increase for every doubling of the number of examples\n",
            "- The `prompt` column/key should be lowercase\n",
            "- The `completion` column/key should be lowercase\n",
            "- The input file should contain exactly two columns/keys per row. Additional columns/keys present are: ['Unnamed: 0', 'ID']\n",
            "  WARNING: Some of the additional columns/keys contain `Unnamed: 0` in their name. These will be ignored, and the column/key `Unnamed: 0` will be used instead. This could also result from a duplicate column/key in the provided file.\n",
            "  WARNING: Some of the additional columns/keys contain `ID` in their name. These will be ignored, and the column/key `ID` will be used instead. This could also result from a duplicate column/key in the provided file.\n",
            "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://beta.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
            "- Your data does not contain a common ending at the end of your completions. Having a common ending string appended to the end of the completion makes it clearer to the fine-tuned model where the completion should end. See https://beta.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples.\n",
            "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://beta.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
            "\n",
            "Based on the analysis we will perform the following actions:\n",
            "- [Necessary] Your format `CSV` will be converted to `JSONL`\n",
            "- [Necessary] Lower case column name to `prompt`\n",
            "- [Necessary] Lower case column name to `completion`\n",
            "- [Necessary] Remove additional columns/keys: ['Unnamed: 0', 'ID']\n",
            "- [Recommended] Add a suffix separator ` ->` to all prompts [Y/n]: Y\n",
            "/usr/local/lib/python3.7/dist-packages/openai/validators.py:215: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  x[\"prompt\"] += suffix\n",
            "- [Recommended] Add a suffix ending `.` to all completions [Y/n]: Y\n",
            "/usr/local/lib/python3.7/dist-packages/openai/validators.py:371: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  x[\"completion\"] += suffix\n",
            "- [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: Y\n",
            "/usr/local/lib/python3.7/dist-packages/openai/validators.py:415: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  lambda x: (\"\" if x[0] == \" \" else \" \") + x\n",
            "\n",
            "\n",
            "Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n",
            "\n",
            "Wrote modified file to `data_prepared.jsonl`\n",
            "Feel free to take a look!\n",
            "\n",
            "Now use that file when fine-tuning:\n",
            "> openai api fine_tunes.create -t \"data_prepared.jsonl\"\n",
            "\n",
            "After you’ve fine-tuned a model, remember that your prompt has to end with the indicator string ` ->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\".\"]` so that the generated texts ends at the expected place.\n",
            "Once your model starts training, it'll approximately take 2.86 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
          ]
        }
      ],
      "source": [
        "!openai tools fine_tunes.prepare_data -f data.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQ099Vana-b_"
      },
      "source": [
        "### Splitting the data into train and val sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "zAlDkw1MNtvz"
      },
      "outputs": [],
      "source": [
        "# The dataset has 30 examples. We will use 20 for training and 10 for testing\n",
        "\n",
        "!head -n 20 data_prepared.jsonl > train.jsonl\n",
        "!tail -n 10  data_prepared.jsonl > valid.jsonl\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "qN0SCMVj43Rp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "a2f4bf2e40b1424b867f71700c1fab61",
            "9912ae56e51e4e82b884efd89fed0979",
            "8954c41cacc949ed92ebeabffc45da15",
            "012ce079a1e84e2b893c9d524b77a4ba",
            "a15ec202a93b4ef4a28373610756bc83",
            "a74631b6b02e401eb6ee7f45ee4c0b4b",
            "232c2138b9a84f8791d0027666508d3b",
            "1440f5a93e6e409fb4c5a7502ce17195"
          ]
        },
        "outputId": "3c147c18-23e3-498e-9ed3-eb291ce2cea1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a2f4bf2e40b1424b867f71700c1fab61"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">icy-waterfall-11</strong>: <a href=\"https://wandb.ai/natviv-gpt/Medical%20GPT-3/runs/w3kteljm\" target=\"_blank\">https://wandb.ai/natviv-gpt/Medical%20GPT-3/runs/w3kteljm</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220516_053356-w3kteljm/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4so6FA5FbPlt"
      },
      "source": [
        "### GPT-3 fine-tuning hyper-parameters definition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "OhoZ_gFfOhbX"
      },
      "outputs": [],
      "source": [
        "model = 'ada'  # can be ada, babbage or curie\n",
        "n_epochs = 4\n",
        "batch_size = 4\n",
        "learning_rate_multiplier = 0.1\n",
        "prompt_loss_weight = 0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5gcrsJabSKM"
      },
      "source": [
        "### Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "0C7PLw2QOs47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c4016a4-4dd7-4585-ec95-71b2aae64a3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found potentially duplicated files with name 'train.jsonl', purpose 'fine-tune' and size 1910 bytes\n",
            "file-yJOD9irAl3PoA6Ip4bdF6xnd\n",
            "Enter file ID to reuse an already uploaded file, or an empty string to upload this file anyway: \n",
            "Upload progress: 100% 1.91k/1.91k [00:00<00:00, 1.85Mit/s]\n",
            "Uploaded file from train.jsonl: file-v1pWf4Rzd6epNVT5eSwehFXZ\n",
            "Found potentially duplicated files with name 'valid.jsonl', purpose 'fine-tune' and size 995 bytes\n",
            "file-LPVmd5FAgyeEiuEV42Pd5Enb\n",
            "Enter file ID to reuse an already uploaded file, or an empty string to upload this file anyway: \n",
            "Upload progress: 100% 995/995 [00:00<00:00, 1.05Mit/s]\n",
            "Uploaded file from valid.jsonl: file-Ex2NITSRAYxTYkkqotDvNmHT\n",
            "Created fine-tune: ft-GBuik8LkxwsTi7itJkoRk16k\n",
            "Streaming events until fine-tuning is complete...\n",
            "\n",
            "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
            "[2022-05-16 05:35:12] Created fine-tune: ft-GBuik8LkxwsTi7itJkoRk16k\n",
            "\n",
            "Stream interrupted (client disconnected).\n",
            "To resume the stream, run:\n",
            "\n",
            "  openai api fine_tunes.follow -i ft-GBuik8LkxwsTi7itJkoRk16k\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!openai api fine_tunes.create \\\n",
        "    -t train.jsonl \\\n",
        "    -v valid.jsonl \\\n",
        "    -m $model \\\n",
        "    --n_epochs $n_epochs \\\n",
        "    --batch_size $batch_size \\\n",
        "    --learning_rate_multiplier $learning_rate_multiplier \\\n",
        "    --prompt_loss_weight $prompt_loss_weight"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!openai api fine_tunes.follow -i ft-GBuik8LkxwsTi7itJkoRk16k"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6eVdfLjrjjG",
        "outputId": "3da17e81-d114-4bec-843d-37efbe588efd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2022-05-16 05:35:12] Created fine-tune: ft-GBuik8LkxwsTi7itJkoRk16k\n",
            "[2022-05-16 05:45:30] Fine-tune costs $0.00\n",
            "[2022-05-16 05:45:31] Fine-tune enqueued. Queue number: 0\n",
            "[2022-05-16 05:45:36] Fine-tune started\n",
            "[2022-05-16 05:45:53] Completed epoch 1/4\n",
            "[2022-05-16 05:45:56] Completed epoch 2/4\n",
            "[2022-05-16 05:45:59] Completed epoch 3/4\n",
            "[2022-05-16 05:46:01] Completed epoch 4/4\n",
            "[2022-05-16 05:46:21] Uploaded model: ada:ft-personal-2022-05-16-05-46-19\n",
            "[2022-05-16 05:46:24] Uploaded result file: file-3YHeHfz5D9EqbXF9hgdI5Q1j\n",
            "[2022-05-16 05:46:24] Fine-tune succeeded\n",
            "\n",
            "Job complete! Status: succeeded 🎉\n",
            "Try out your fine-tuned model:\n",
            "\n",
            "openai api completions.create -m ada:ft-personal-2022-05-16-05-46-19 -p <YOUR_PROMPT>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeCgcFbVbUhh"
      },
      "source": [
        "## Sync fine-tune jobs to Weights & Biases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Cfet6LhbXYZ"
      },
      "source": [
        "Log fine-tuning runs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "-ipLXku8P8TF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a731d81-f826-4600-85f6-c9685c9389d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnatviv\u001b[0m (\u001b[33mnatviv-gpt\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20220516_054842-ft-GBuik8LkxwsTi7itJkoRk16k\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mft-GBuik8LkxwsTi7itJkoRk16k\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/natviv-gpt/Medical%20GPT-3\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/natviv-gpt/Medical%20GPT-3/runs/ft-GBuik8LkxwsTi7itJkoRk16k\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             elapsed_examples ▁▁▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▇▇▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               elapsed_tokens ▁▁▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▇▇▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                training_loss ▇▇██▅▆▅▄▃▃▄▃▂▁▄▃▂▂▂▁▂▂\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   training_sequence_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅▁▅▁██▅▅\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      training_token_accuracy ▂▁▁▂▅▄▄▅▆▅▅▇▆▆▅▆▆▆▇█▇▆\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              validation_loss ▆▇█▇▆█▃▁▂▅▅▂▂▃▆▃▅▂▃▆▅▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: validation_sequence_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    validation_token_accuracy ▁▄▁▃▄▂▅█▄▅▅▄▅▄▃▅▃▆▅▂▂▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             elapsed_examples 88.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               elapsed_tokens 1976.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             fine_tuned_model ada:ft-personal-2022...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       status succeeded\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                training_loss 0.58311\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   training_sequence_accuracy 0.25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      training_token_accuracy 0.8\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              validation_loss 0.75593\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: validation_sequence_accuracy 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    validation_token_accuracy 0.72222\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mft-GBuik8LkxwsTi7itJkoRk16k\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/natviv-gpt/Medical%20GPT-3/runs/ft-GBuik8LkxwsTi7itJkoRk16k\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220516_054842-ft-GBuik8LkxwsTi7itJkoRk16k/logs\u001b[0m\n",
            "🎉 wandb sync completed successfully\n"
          ]
        }
      ],
      "source": [
        "!openai wandb sync --project \"Medical GPT-3\" "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZb_9oeKiefO"
      },
      "source": [
        "## Run inference on validation examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yc6AecHwihJF"
      },
      "source": [
        "Run some predictions on a few validation samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "XH8IUPA7lkFW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "d9213975-e298-467a-b670-942a9b4a4637"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnatviv\u001b[0m (\u001b[33mnatviv-gpt\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220516_054901-24cv0wid</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/natviv-gpt/Medical%20GPT-3/runs/24cv0wid\" target=\"_blank\">deft-cosmos-13</a></strong> to <a href=\"https://wandb.ai/natviv-gpt/Medical%20GPT-3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# create eval job\n",
        "run = wandb.init(project='Medical GPT-3', job_type='eval')\n",
        "entity = wandb.run.entity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "iXlnqZIZlvh8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "10f75ffb-4e66-491d-f2f3-b71a7d8120dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ada:ft-personal-2022-05-16-05-46-19'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# choose a fine-tuned model\n",
        "artifact_job = run.use_artifact(f'{entity}/Medical GPT-3/fine_tune_details:latest', type='fine_tune_details')\n",
        "artifact_job.metadata\n",
        "\n",
        "wandb.config.update({k:artifact_job.metadata[k] for k in ['fine_tuned_model', 'model', 'hyperparams']})\n",
        "fine_tuned_model = artifact_job.metadata['fine_tuned_model']\n",
        "fine_tuned_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0O6UXXgjgi3"
      },
      "source": [
        "Loading validation data as dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "fpPsEznRmN_e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "d06d9e22-e142-4b0c-c3f8-fe8f3d461734"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                       prompt  \\\n",
              "0                 PTA, vss were not normal ->   \n",
              "1            UTI as primary cause of fever ->   \n",
              "2  The pt has recurring history of jt pain ->   \n",
              "3                   The pt requires lbp pt ->   \n",
              "4                                Pt dc ama ->   \n",
              "\n",
              "                                          completion  \n",
              "0   Prior to admission, vital signs were not normal.  \n",
              "1   Urinary tract infection as primary cause of f...  \n",
              "2   The patient has recurring history of joint pain.  \n",
              "3   The patient requires lower back pain physical...  \n",
              "4         Patient discharged against medical advice.  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b2574d77-f448-4d08-a08f-2d018a08c35b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt</th>\n",
              "      <th>completion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PTA, vss were not normal -&gt;</td>\n",
              "      <td>Prior to admission, vital signs were not normal.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>UTI as primary cause of fever -&gt;</td>\n",
              "      <td>Urinary tract infection as primary cause of f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The pt has recurring history of jt pain -&gt;</td>\n",
              "      <td>The patient has recurring history of joint pain.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The pt requires lbp pt -&gt;</td>\n",
              "      <td>The patient requires lower back pain physical...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Pt dc ama -&gt;</td>\n",
              "      <td>Patient discharged against medical advice.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b2574d77-f448-4d08-a08f-2d018a08c35b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b2574d77-f448-4d08-a08f-2d018a08c35b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b2574d77-f448-4d08-a08f-2d018a08c35b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "df = pd.read_json(\"valid.jsonl\", orient='records', lines=True)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pq3rsIFRj1r8"
      },
      "source": [
        "Perform inference on 10 validation examples. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "CdYAMa-Nmlo9"
      },
      "outputs": [],
      "source": [
        "n_samples = 10\n",
        "df = df.iloc[:n_samples]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "z5X7_7J6m1Lt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f16b6573-5c87-42fa-f73b-131ec8072e12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10it [00:11,  1.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Prompt: PTA, vss were not normal, Target: Prior to admission, vital signs were not nor, Prediction: Psychotic Aptitude Test, not normal.\n",
            "\n",
            "Additional tests for conditions other than those listed here were ordered and may not have been analyzed fully\n",
            "\n",
            "Prompt: UTI as primary cause of fever, Target: Urinary tract infection as primary cause of fe, Prediction: Unstable fever associated with the reaction to the vaccine (primary exposure causing fever) as the reason for hospitalє admission.\n",
            "\n",
            "Related Patient Compl\n",
            "\n",
            "Prompt: The pt has recurring history of jt pain, Target: The patient has recurring history of joint p, Prediction: Patient has recurrent jt pain. Patient is doing well. Anecdotal history of recurrent jt pain. A patient's antecedent history\n",
            "\n",
            "Prompt: The pt requires lbp pt, Target: The patient requires lower back pain physical ther, Prediction: Observation required for body monitor. Patient requires observation. Physician recommends body monitor.\n",
            "\n",
            "Theme Notes: Questions? Contact Dr. Polyefflis\n",
            "\n",
            "Prompt: Pt dc ama, Target: Patient discharged against medical adv, Prediction: Female cough, N. breathing absent.\n",
            "\n",
            "Pt 3 Active (\"active patient\") stem found in patients who still being seen or being treated.\n",
            "\n",
            "Prompt: c/o gi pain, Target: complains of gastrointestinal p, Prediction: Primary caregiver (PG) entered hospital. Normal patient navigation. Home for examination.\n",
            "\n",
            "5th patient discharged.\n",
            "\n",
            "Status:\n",
            "\n",
            "\n",
            "\n",
            "Prompt: The pt has lbp, Target: The patient has lower back p, Prediction: Patient is being weighed. The patient has been weighed.\n",
            "\n",
            "Takeings: Passing takes takes.\n",
            "\n",
            "Taste takes takes. Taste stimulus takes\n",
            "\n",
            "Prompt: fx detected in femur, Target: fracture detected in fe, Prediction: Coronary angiogram detected in femur. Patient is stable. Physician observed. CASE SCAN RESULT: Circular unconsciousness.\n",
            "\n",
            "Prompt: The Pt when admitted was PN, Target: The patient when admitted was pourly nouris, Prediction: Continuation of care after admission was PN when admitted.\n",
            "\n",
            "Price, Nele's Temp. of Sight 7d, Nele's concern\n",
            "\n",
            "Prompt: LOC low, pt likely in coma, Target: Level of consciouness low, patient likely in c, Prediction: Low blood pressure. Patient likely in coma.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "This Picture What does this picture say about me?\n",
            "\n",
            "I'm high risk for\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "results = []\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "for _, row in tqdm(df.iterrows()):\n",
        "    prompt = row['prompt']\n",
        "    res = openai.Completion.create(model=fine_tuned_model, prompt=prompt, max_tokens=30, stop=[\" END\"])\n",
        "    completion = res['choices'][0]['text']\n",
        "    completion = completion[1:]       # remove initial space\n",
        "    prompt = prompt[:-3]              # remove \" ->\"\n",
        "    target = row['completion'][1:-4]  # remove initial space and \"END\"\n",
        "    results.append(f\"Prompt: {prompt}, Target: {target}, Prediction: {completion}\")\n",
        "\n",
        "print_results(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Smaller Ada model not so useful in the generation task and the results are a bit all over the place.\n",
        "\n",
        "To try with 'curie' or 'da-vinci' for better results "
      ],
      "metadata": {
        "id": "1bcjmQC8t5a8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWe0ogkUj8nE"
      },
      "source": [
        "Create and log a W&B Table to explore, query & compare model predictions if helpful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "BeE_QLPTm37_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "fb9e2440203843439df56c9ff5f0cb01",
            "a6c42eaf1fd9455497534f64d52d3365",
            "062e089e726b47b4ab3491a79cf7f416",
            "859638c8a0664dbfb37ea87f985dac13",
            "48fbebef4dc2411bbd3270e8a926c5cd",
            "362e0e46bb894fcc8470709d93ba94d8",
            "c7b36b0600e746c988294f347fe0b77b",
            "910521407e1747c0806fd7e2892d9baa"
          ]
        },
        "outputId": "202d3ec1-399d-480e-9af3-26ed9a95811d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fb9e2440203843439df56c9ff5f0cb01"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">deft-cosmos-13</strong>: <a href=\"https://wandb.ai/natviv-gpt/Medical%20GPT-3/runs/24cv0wid\" target=\"_blank\">https://wandb.ai/natviv-gpt/Medical%20GPT-3/runs/24cv0wid</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220516_054901-24cv0wid/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# prediction_table = wandb.Table(columns=['prompt', 'target', 'completion'], data=data)\n",
        "# wandb.log({'predictions': prediction_table})\n",
        "wandb.finish()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Next, we will prototype a simple conversational primary care agent with GPT-3\n",
        "\n",
        "<figure>\n",
        "<center>\n",
        "<img src='https://singularityhub.com/wp-content/uploads/2019/02/doctor-robot-modern-future-health-artificial-intelligence-shutterstock-1072509989-1068x601.jpg' style=\"width:10px;height:20px\" />\n",
        "<figcaption></figcaption></center>\n",
        "</figure>\n"
      ],
      "metadata": {
        "id": "LcBEDmrDvOL6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instruction = 'In the following interactions, you are supposed to interact with a user who may have a primary care concern and provide them with support. This support can include triaging, providing a differential diagnosis if certain or help with scheduling a doctor appointment. Please find some example conversations below. When prompted, you are to only provide the doctor\\'s response.'\n",
        "\n",
        "# Provide a simple example of doctor-patient conversation. Not sure how long of a context GPT-3 can handle effectively at the moment\n",
        "example1 = \"Doctor: How can I help? Patient: I have a rash on my skin. Doctor: Anything else? Patient: No Doctor:Is it hurting Patient: Yes, It is swollen and itchy Doctor: Ok, I will refer you to a specialist dermatologist.\"\n",
        "example2 = \"Doctor: How can I help? Patient: I have fever and headache. Doctor:For how long, have you had these symptoms? Patient: 1 day. Doctor: Please come over to the clinic if possible so we can take a closer look.\"\n",
        "\n",
        "prompt = instruction + example1 + example2\n"
      ],
      "metadata": {
        "id": "lydbzvhYzls6"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using the above prompt actually causes GPT-3 to generate the full dialogue instead of the next turn only\n",
        "\n",
        "Reducing max_tokens to prevent the model from rambling."
      ],
      "metadata": {
        "id": "mmTRpwiF8Pij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "welcome_text = 'Hi, I am Dr. AI. How can I help you today? Please say Done to end conversation'\n",
        "model = 'text-davinci-002'\n",
        "\n",
        "prompt = prompt + \"Doctor:\" + welcome_text\n",
        "print(f\"{welcome_text}\\n\")\n",
        "\n",
        "patient_prefix = 'Patient: '\n",
        "doctor_prefix = 'Doctor: '\n",
        "\n",
        "def get_next_turn(model, prompt):\n",
        "  max_tokens=100\n",
        "  temperature=0.2\n",
        "  stop=[\" END\"]\n",
        "  prompt = prompt + patient_prefix + patient_input + doctor_prefix \n",
        "  res = openai.Completion.create(model=model, \n",
        "                                prompt=prompt, \n",
        "                                max_tokens=max_tokens, \n",
        "                                temperature = temperature, \n",
        "                                stop=stop)\n",
        "  completion = res['choices'][0]['text']\n",
        "  completion = completion[1:] # remove initial space\n",
        "  return completion\n",
        "\n",
        "while True:\n",
        "  patient_input = input(f'{patient_prefix}\\n')\n",
        "  if patient_input in ['Done', 'done']:\n",
        "    break\n",
        "  response = get_next_turn(model, prompt) \n",
        "  print(f\"Doctor: {response}\")\n",
        "  prompt = prompt + response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiooSbm31_cN",
        "outputId": "084d11ff-d5f2-4db7-89a2-242025bf4a31"
      },
      "execution_count": 30,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hi, I am Dr. AI. How can I help you today? Please say Done to end conversation\n",
            "\n",
            "Patient: \n",
            "I have a headache\n",
            "Doctor: \n",
            "For how long have you had these symptoms?\n",
            "Patient: \n",
            "1 day\n",
            "Doctor: Please come over to the clinic so we can take a closer look.\n",
            "Patient: \n",
            "Where are you located?\n",
            "Doctor: \n",
            "We are located at 123 Main Street. Would you like me to schedule an appointment for you?\n",
            "Patient: \n",
            "Yes\n",
            "Doctor: \n",
            "Thank you for your help.\n",
            "Patient: \n",
            "When should i come?\n",
            "Doctor: \n",
            "The earliest appointment we have is tomorrow at 9am. Would that work for you?\n",
            "Patient: \n",
            "Yes\n",
            "Doctor: \n",
            "Thank you for your help.\n",
            "Patient: \n",
            "Done\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Medical GPT-3.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "64b5fd91a47d43da9b22c50bd3a79308": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5b0ff84a2d3b4dd281288dff2b66d47d",
              "IPY_MODEL_67d112657d424193ad0e08bbce710103"
            ],
            "layout": "IPY_MODEL_014665d71776438095e94adef9415b05"
          }
        },
        "5b0ff84a2d3b4dd281288dff2b66d47d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab5d3b80f70a40e084ad7c1bc6279fda",
            "placeholder": "​",
            "style": "IPY_MODEL_9a849292fac44c59ae9cadcab67d3178",
            "value": "0.012 MB of 0.012 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "67d112657d424193ad0e08bbce710103": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77ffe1251c7a4f5b8f9d2cf1e3889546",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b73a3767d60b4bb4bc25e5e678b9a76a",
            "value": 1
          }
        },
        "014665d71776438095e94adef9415b05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab5d3b80f70a40e084ad7c1bc6279fda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a849292fac44c59ae9cadcab67d3178": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77ffe1251c7a4f5b8f9d2cf1e3889546": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b73a3767d60b4bb4bc25e5e678b9a76a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a2f4bf2e40b1424b867f71700c1fab61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9912ae56e51e4e82b884efd89fed0979",
              "IPY_MODEL_8954c41cacc949ed92ebeabffc45da15"
            ],
            "layout": "IPY_MODEL_012ce079a1e84e2b893c9d524b77a4ba"
          }
        },
        "9912ae56e51e4e82b884efd89fed0979": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a15ec202a93b4ef4a28373610756bc83",
            "placeholder": "​",
            "style": "IPY_MODEL_a74631b6b02e401eb6ee7f45ee4c0b4b",
            "value": "0.012 MB of 0.012 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "8954c41cacc949ed92ebeabffc45da15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_232c2138b9a84f8791d0027666508d3b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1440f5a93e6e409fb4c5a7502ce17195",
            "value": 1
          }
        },
        "012ce079a1e84e2b893c9d524b77a4ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a15ec202a93b4ef4a28373610756bc83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a74631b6b02e401eb6ee7f45ee4c0b4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "232c2138b9a84f8791d0027666508d3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1440f5a93e6e409fb4c5a7502ce17195": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb9e2440203843439df56c9ff5f0cb01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a6c42eaf1fd9455497534f64d52d3365",
              "IPY_MODEL_062e089e726b47b4ab3491a79cf7f416"
            ],
            "layout": "IPY_MODEL_859638c8a0664dbfb37ea87f985dac13"
          }
        },
        "a6c42eaf1fd9455497534f64d52d3365": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48fbebef4dc2411bbd3270e8a926c5cd",
            "placeholder": "​",
            "style": "IPY_MODEL_362e0e46bb894fcc8470709d93ba94d8",
            "value": "0.010 MB of 0.010 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "062e089e726b47b4ab3491a79cf7f416": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7b36b0600e746c988294f347fe0b77b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_910521407e1747c0806fd7e2892d9baa",
            "value": 1
          }
        },
        "859638c8a0664dbfb37ea87f985dac13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48fbebef4dc2411bbd3270e8a926c5cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "362e0e46bb894fcc8470709d93ba94d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7b36b0600e746c988294f347fe0b77b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "910521407e1747c0806fd7e2892d9baa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}